{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "GAN_final.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "F1letmS5d4L2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "outputId": "224ff6b8-b72f-4627-812f-a86da55ca3cd"
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "##Library \n",
        "import sys\n",
        "# !{sys.executable} -m pip install music21 \n",
        "\n",
        "##Utility Libraries\n",
        "import os, glob, pickle, music21\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from time import time\n",
        "from zipfile import ZipFile \n",
        "from music21 import *\n",
        "from music21 import converter, instrument, note, chord, stream\n",
        "\n",
        "##Keras\n",
        "from keras import backend as K\n",
        "if K.backend()=='tensorflow':\n",
        "    K.set_image_data_format('channels_last')\n",
        "\n",
        "from keras.models import Model, Sequential, load_model\n",
        "from keras.utils import np_utils\n",
        "from keras.callbacks import ModelCheckpoint, History\n",
        "\n",
        "from keras.layers import Dense, Dropout, LSTM, Bidirectional, Activation, Input, Dense\n",
        "from keras.layers import Activation, BatchNormalization, Flatten, ZeroPadding2D, Reshape\n",
        "from keras.layers import BatchNormalization as BatchNorm\n",
        "from keras.layers import CuDNNGRU, CuDNNLSTM\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "\n",
        "from keras.models import Sequential, Model\n",
        "from keras.utils import np_utils\n",
        "\n",
        "from keras.optimizers import Adam,RMSprop,SGD\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "##Tensorflow\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import callbacks\n",
        "from tensorflow.keras.callbacks import EarlyStopping, TensorBoard\n",
        "\n",
        "tf.debugging.set_log_device_placement(True)\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r0QpMH9dd4L6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "6b6164c8-faaa-4d7f-a001-427962bc1720"
      },
      "source": [
        "print(\"Keras is installed and is version: \", tf.keras.__version__)\n",
        "print(\"Tensorflow is installed and is version: \",  tf.__version__)\n",
        "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Keras is installed and is version:  2.2.4-tf\n",
            "Tensorflow is installed and is version:  1.15.0\n",
            "Num GPUs Available:  1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zhcd6taffG92",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1e0e3d62-fa0d-4fba-95e1-4aaa29c86ee2"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yg1_FF9yxz2I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##Add seed to get reproducible results\n",
        "from numpy.random import seed\n",
        "seed(1)\n",
        "from tensorflow import set_random_seed\n",
        "set_random_seed(2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9hQv9pAVxsjC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#https://www.tensorflow.org/tensorboard/get_started\n",
        "\n",
        "\"\"\"Helper Functions\"\"\"\n",
        "class TrainValTensorBoard(TensorBoard):\n",
        "    def __init__(self, log_dir='./logs', **kwargs):\n",
        "        # Make the original `TensorBoard` log to a subdirectory 'training'\n",
        "        training_log_dir = os.path.join(log_dir, 'training')\n",
        "        super(TrainValTensorBoard, self).__init__(training_log_dir, **kwargs)\n",
        "\n",
        "        # Log the validation metrics to a separate subdirectory\n",
        "        self.val_log_dir = os.path.join(log_dir, 'validation')\n",
        "\n",
        "    def set_model(self, model):\n",
        "        # Setup writer for validation metrics\n",
        "        self.val_writer = tf.summary.FileWriter(self.val_log_dir)\n",
        "        super(TrainValTensorBoard, self).set_model(model)\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        # Pop the validation logs and handle them separately with\n",
        "        # `self.val_writer`. Also rename the keys so that they can\n",
        "        # be plotted on the same figure with the training metrics\n",
        "        logs = logs or {}\n",
        "        val_logs = {k.replace('val_', ''): v for k, v in logs.items() if k.startswith('val_')}\n",
        "        for name, value in val_logs.items():\n",
        "            summary = tf.Summary()\n",
        "            summary_value = summary.value.add()\n",
        "            #summary_value.simple_value = value.item()\n",
        "            summary_value.tag = name\n",
        "            self.val_writer.add_summary(summary, epoch)\n",
        "        self.val_writer.flush()\n",
        "\n",
        "        # Pass the remaining logs to `TensorBoard.on_epoch_end`\n",
        "        logs = {k: v for k, v in logs.items() if not k.startswith('val_')}\n",
        "        super(TrainValTensorBoard, self).on_epoch_end(epoch, logs)\n",
        "\n",
        "    def on_train_end(self, logs=None):\n",
        "        super(TrainValTensorBoard, self).on_train_end(logs)\n",
        "        self.val_writer.close()  \n",
        "                \n",
        "## Code adapted from Section\n",
        "def plot(history):\n",
        "    acc = history.history['acc']\n",
        "    loss = history.history['loss']\n",
        "\n",
        "    epochs = range(len(acc))\n",
        "    plt.plot(epochs, acc, 'g-', label='Training accuracy', color = 'darkred')\n",
        "    plt.xlabel(\"Num of Epochs\")\n",
        "    plt.ylabel(\"Accuracy\")\n",
        "    plt.title('Training accuracy')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.figure()\n",
        " \n",
        "    plt.plot(epochs, loss, 'g-', label='Training loss', color = 'darkred')\n",
        "    plt.xlabel(\"Num of Epochs\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.title('Training loss')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h0EXyIlhyHQc",
        "colab_type": "text"
      },
      "source": [
        "----------\n",
        "# 1.Read in Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f8NYWkFVd4MB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "bf6a4aa4-ab66-4715-c3a5-0d9709e2c9bb"
      },
      "source": [
        "#Unzipping compressed data folder\n",
        "file_name = \"/content/gdrive/My Drive/midi_songs.zip\"\n",
        "  \n",
        "# opening the zip file in READ mode \n",
        "with ZipFile(file_name, 'r') as zip: \n",
        "    # printing all the contents of the zip file \n",
        "    # zip.printdir() \n",
        "  \n",
        "    # extracting all the files \n",
        "    print(\"Extracting all the files now...\") \n",
        "    zip.extractall() \n",
        "    print(\"Done!\") "
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Extracting all the files now...\n",
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UaSEIJUWjgK8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# def get_midi_pattern():\n",
        "#   for file in glob.glob(\"Pokemon MIDIs/*.mid\"):\n",
        "#     try:\n",
        "#       return music21.midi.getNumbersAsList(file)\n",
        "#     except:\n",
        "#       print ('Error reading {}'.format(file))\n",
        "#       return None\n",
        "\n",
        "# midi_pattern = get_midi_pattern()\n",
        "\n",
        "# def get_tones(midi_pattern):\n",
        "#   \"\"\"\n",
        "#   returns a dict of statistics, keys: [scale_distribution,\n",
        "#   \"\"\"\n",
        "  \n",
        "#   tones = []\n",
        "  \n",
        "#   for track in midi_pattern:\n",
        "#     for event in track:\n",
        "#       if type(event) == midi.events.SetTempoEvent:\n",
        "#         pass # These are currently ignored\n",
        "#       elif (type(event) == midi.events.NoteOffEvent) or \\\n",
        "#            (type(event) == midi.events.NoteOnEvent and \\\n",
        "#             event.velocity == 0):\n",
        "#         pass # not needed here\n",
        "#       elif type(event) == midi.events.NoteOnEvent:\n",
        "#         tones.append(event.data[0])\n",
        "#   return tones \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DDu2YuCZzckx",
        "colab_type": "text"
      },
      "source": [
        "-----------\n",
        "# 2. Data Processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_d-OFaCEDqzN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_notes():\n",
        "    \"\"\" Get all the notes and chords from the midi files \"\"\"\n",
        "    with open('data/notes', 'rb') as filepath:\n",
        "        notes = pickle.load(filepath)\n",
        "    # notes = []\n",
        "\n",
        "    # for file in glob.glob(\"/content/Pokemon MIDIs/*.mid\"):\n",
        "    #     midi = converter.parse(file)\n",
        "\n",
        "    #     print(\"Parsing %s\" % file)\n",
        "\n",
        "    #     notes_to_parse = None\n",
        "\n",
        "    #     try: # file has instrument parts\n",
        "    #         s2 = instrument.partitionByInstrument(midi)\n",
        "    #         notes_to_parse = s2.parts[0].recurse() \n",
        "    #     except: # file has notes in a flat structure\n",
        "    #         notes_to_parse = midi.flat.notes\n",
        "            \n",
        "    #     for element in notes_to_parse:\n",
        "    #         if isinstance(element, note.Note):\n",
        "    #             notes.append(str(element.pitch))\n",
        "    #         elif isinstance(element, chord.Chord):\n",
        "    #             notes.append('.'.join(str(n) for n in element.normalOrder))\n",
        "\n",
        "    # with open('data/notes', 'wb') as filepath:\n",
        "    #     pickle.dump(notes, filepath)\n",
        "\n",
        "    return notes\n",
        "\n",
        "def prepare_sequences(notes, n_vocab):\n",
        "    \"\"\" Prepare the sequences used by the Neural Network \"\"\"\n",
        "    sequence_length = 100\n",
        "\n",
        "    # Get all pitch names\n",
        "    pitchnames = sorted(set(item for item in notes))\n",
        "\n",
        "    # Create a dictionary to map pitches to integers\n",
        "    note_to_int = dict((note, number) for number, note in enumerate(pitchnames))\n",
        "\n",
        "    network_input = []\n",
        "    network_output = []\n",
        "\n",
        "    # create input sequences and the corresponding outputs\n",
        "    for i in range(0, len(notes) - sequence_length, 1):\n",
        "        sequence_in = notes[i:i + sequence_length]\n",
        "        sequence_out = notes[i + sequence_length]\n",
        "        network_input.append([note_to_int[char] for char in sequence_in])\n",
        "        network_output.append(note_to_int[sequence_out])\n",
        "\n",
        "    n_patterns = len(network_input)\n",
        "\n",
        "    # Reshape the input into a format compatible with LSTM layers\n",
        "    network_input = np.reshape(network_input, (n_patterns, sequence_length, 1))\n",
        "    \n",
        "    # Normalize input between -1 and 1\n",
        "    network_input = (network_input - float(n_vocab)/2) / (float(n_vocab)/2)\n",
        "    network_output = np_utils.to_categorical(network_output)\n",
        "\n",
        "    return (network_input, network_output)\n",
        "\n",
        "def generate_notes(model, network_input, n_vocab):\n",
        "    \"\"\" Generate notes from the neural network based on a sequence of notes \"\"\"\n",
        "    # pick a random sequence from the input as a starting point for the prediction\n",
        "    start = numpy.random.randint(0, len(network_input)-1)\n",
        "    \n",
        "    # Get pitch names and store in a dictionary\n",
        "    pitchnames = sorted(set(item for item in notes))\n",
        "    int_to_note = dict((number, note) for number, note in enumerate(pitchnames))\n",
        "\n",
        "    pattern = network_input[start]\n",
        "    prediction_output = []\n",
        "\n",
        "    # generate 500 notes\n",
        "    for note_index in range(500):\n",
        "        prediction_input = numpy.reshape(pattern, (1, len(pattern), 1))\n",
        "        prediction_input = prediction_input / float(n_vocab)\n",
        "\n",
        "        prediction = model.predict(prediction_input, verbose=0)\n",
        "\n",
        "        index = numpy.argmax(prediction)\n",
        "        result = int_to_note[index]\n",
        "        prediction_output.append(result)\n",
        "        \n",
        "        pattern = numpy.append(pattern,index)\n",
        "        #pattern.append(index)\n",
        "        pattern = pattern[1:len(pattern)]\n",
        "\n",
        "    return prediction_output\n",
        "  \n",
        "def create_midi(prediction_output, filename):\n",
        "    \"\"\" convert the output from the prediction to notes and create a midi file\n",
        "        from the notes \"\"\"\n",
        "    offset = 0\n",
        "    output_notes = []\n",
        "\n",
        "    # create note and chord objects based on the values generated by the model\n",
        "    for item in prediction_output:\n",
        "        pattern = item[0]\n",
        "        # pattern is a chord\n",
        "        if ('.' in pattern) or pattern.isdigit():\n",
        "            notes_in_chord = pattern.split('.')\n",
        "            notes = []\n",
        "            for current_note in notes_in_chord:\n",
        "                new_note = note.Note(int(current_note))\n",
        "                new_note.storedInstrument = instrument.Piano()\n",
        "                notes.append(new_note)\n",
        "            new_chord = chord.Chord(notes)\n",
        "            new_chord.offset = offset\n",
        "            output_notes.append(new_chord)\n",
        "        # pattern is a note\n",
        "        else:\n",
        "            new_note = note.Note(pattern)\n",
        "            new_note.offset = offset\n",
        "            new_note.storedInstrument = instrument.Piano()\n",
        "            output_notes.append(new_note)\n",
        "\n",
        "        # increase offset each iteration so that notes do not stack\n",
        "        offset += 0.5\n",
        "\n",
        "    midi_stream = stream.Stream(output_notes)\n",
        "    midi_stream.write('midi', fp='{}.mid'.format(filename))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vkFwIoV5PlR2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c1449aba-f31a-42cb-8bf5-efd5fd8bd0c4"
      },
      "source": [
        "len(get_notes())"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "163685"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7BXyZFnvCqOR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class GAN():\n",
        "    def __init__(self, rows):\n",
        "        self.seq_length = rows\n",
        "        self.seq_shape = (self.seq_length, 1)\n",
        "        self.latent_dim = 1000\n",
        "        self.disc_loss = []\n",
        "        self.gen_loss =[]\n",
        "        \n",
        "        optimizer = Adam(0.0002, 0.5)\n",
        "\n",
        "        # Build and compile the discriminator\n",
        "        self.discriminator = self.build_discriminator()\n",
        "        self.discriminator.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "\n",
        "        # Build the generator\n",
        "        self.generator = self.build_generator()\n",
        "\n",
        "        # The generator takes noise as input and generates note sequences\n",
        "        z = Input(shape=(self.latent_dim,))\n",
        "        generated_seq = self.generator(z)\n",
        "\n",
        "        # For the combined model we will only train the generator\n",
        "        self.discriminator.trainable = False\n",
        "\n",
        "        # The discriminator takes generated images as input and determines validity\n",
        "        validity = self.discriminator(generated_seq)\n",
        "\n",
        "        # The combined model  (stacked generator and discriminator)\n",
        "        # Trains the generator to fool the discriminator\n",
        "        self.combined = Model(z, validity)\n",
        "        self.combined.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
        "\n",
        "    def build_discriminator(self):\n",
        "\n",
        "        model = Sequential()\n",
        "        model.add(CuDNNLSTM(512, input_shape=self.seq_shape, return_sequences=True))\n",
        "        model.add(Bidirectional(CuDNNLSTM(512)))\n",
        "        model.add(Dense(512))\n",
        "        model.add(LeakyReLU(alpha=0.2))\n",
        "        model.add(Dense(256))\n",
        "        model.add(LeakyReLU(alpha=0.2))\n",
        "        model.add(Dense(1, activation='sigmoid'))\n",
        "        model.summary()\n",
        "\n",
        "        seq = Input(shape=self.seq_shape)\n",
        "        validity = model(seq)\n",
        "\n",
        "        return Model(seq, validity)\n",
        "      \n",
        "    def build_generator(self):\n",
        "\n",
        "        model = Sequential()\n",
        "        model.add(Dense(256, input_dim=self.latent_dim))\n",
        "        model.add(LeakyReLU(alpha=0.2))\n",
        "        model.add(BatchNormalization(momentum=0.8))\n",
        "        model.add(Dense(512))\n",
        "        model.add(LeakyReLU(alpha=0.2))\n",
        "        model.add(BatchNormalization(momentum=0.8))\n",
        "        model.add(Dense(1024))\n",
        "        model.add(LeakyReLU(alpha=0.2))\n",
        "        model.add(BatchNormalization(momentum=0.8))\n",
        "        model.add(Dense(np.prod(self.seq_shape), activation='tanh'))\n",
        "        model.add(Reshape(self.seq_shape))\n",
        "        model.summary()\n",
        "        \n",
        "        noise = Input(shape=(self.latent_dim,))\n",
        "        seq = model(noise)\n",
        "\n",
        "        return Model(noise, seq)\n",
        "\n",
        "    def train(self, epochs, batch_size=128, sample_interval=50):\n",
        "\n",
        "        # Load and convert the data\n",
        "        notes = get_notes()\n",
        "        n_vocab = len(set(notes))\n",
        "        X_train, y_train = prepare_sequences(notes, n_vocab)\n",
        "\n",
        "        # Adversarial ground truths\n",
        "        real = np.ones((batch_size, 1))\n",
        "        fake = np.zeros((batch_size, 1))\n",
        "        \n",
        "        # Training the model\n",
        "        for epoch in range(epochs):\n",
        "\n",
        "            # Training the discriminator\n",
        "            # Select a random batch of note sequences\n",
        "            idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
        "            real_seqs = X_train[idx]\n",
        "\n",
        "            #noise = np.random.choice(range(484), (batch_size, self.latent_dim))\n",
        "            #noise = (noise-242)/242\n",
        "            noise = np.random.normal(0, 1, (batch_size, self.latent_dim))\n",
        "\n",
        "            # Generate a batch of new note sequences\n",
        "            gen_seqs = self.generator.predict(noise)\n",
        "\n",
        "            # Train the discriminator\n",
        "            d_loss_real = self.discriminator.train_on_batch(real_seqs, real)\n",
        "            d_loss_fake = self.discriminator.train_on_batch(gen_seqs, fake)\n",
        "            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
        "\n",
        "\n",
        "            #  Training the Generator\n",
        "            noise = np.random.normal(0, 1, (batch_size, self.latent_dim))\n",
        "\n",
        "            # Train the generator (to have the discriminator label samples as real)\n",
        "            g_loss = self.combined.train_on_batch(noise, real)\n",
        "\n",
        "            # Print the progress and save into loss lists\n",
        "            if epoch % sample_interval == 0:\n",
        "              print (\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (epoch, d_loss[0], 100*d_loss[1], g_loss))\n",
        "              self.disc_loss.append(d_loss[0])\n",
        "              self.gen_loss.append(g_loss)\n",
        "        \n",
        "        self.generate(notes)\n",
        "        self.plot_loss()\n",
        "        \n",
        "    def generate(self, input_notes):\n",
        "        # Get pitch names and store in a dictionary\n",
        "        notes = input_notes\n",
        "        pitchnames = sorted(set(item for item in notes))\n",
        "        int_to_note = dict((number, note) for number, note in enumerate(pitchnames))\n",
        "        \n",
        "        # Use random noise to generate sequences\n",
        "        noise = np.random.normal(0, 1, (1, self.latent_dim))\n",
        "        predictions = self.generator.predict(noise)\n",
        "        \n",
        "        pred_notes = [x*242+242 for x in predictions[0]]\n",
        "        pred_notes = [int_to_note[int(x)] for x in pred_notes]\n",
        "        \n",
        "        create_midi(pred_notes, 'gan_final')\n",
        "        \n",
        "    def plot_loss(self):\n",
        "        plt.plot(self.disc_loss, c='red')\n",
        "        plt.plot(self.gen_loss, c='blue')\n",
        "        plt.title(\"GAN Loss per Epoch\")\n",
        "        plt.legend(['Discriminator', 'Generator'])\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.ylabel('Loss')\n",
        "        plt.savefig('GAN_Loss_per_Epoch_final.png', transparent=True)\n",
        "        # plt.close()\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wwDtnbJUCyO2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gan = GAN(rows=100)    \n",
        "gan.train(epochs=30000, batch_size=32, sample_interval=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yw-pD2M_629L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}