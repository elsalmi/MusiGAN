{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F1letmS5d4L2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "##Library \n",
    "import sys\n",
    "# !{sys.executable} -m pip install music21 \n",
    "\n",
    "##Utility Libraries\n",
    "import os, glob, pickle, music21\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from time import time\n",
    "from zipfile import ZipFile \n",
    "from music21 import *\n",
    "from music21 import converter, instrument, note, chord, stream\n",
    "\n",
    "##Keras\n",
    "from keras import backend as K\n",
    "if K.backend()=='tensorflow':\n",
    "    K.set_image_data_format('channels_last')\n",
    "\n",
    "import keras\n",
    "from keras.models import Model, Sequential, load_model\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import ModelCheckpoint, History, TensorBoard\n",
    "\n",
    "from keras.layers import Dense, Dropout, LSTM, Bidirectional, Activation, Input, Dense\n",
    "from keras.layers import Activation, BatchNormalization, Flatten, ZeroPadding2D, Reshape\n",
    "from keras.layers import BatchNormalization as BatchNorm\n",
    "from keras.layers import CuDNNGRU, CuDNNLSTM\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.utils import np_utils\n",
    "\n",
    "from keras.optimizers import Adam,RMSprop,SGD\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "##Tensorflow\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import callbacks\n",
    "from tensorflow.keras.callbacks import EarlyStopping, TensorBoard\n",
    "\n",
    "tf.debugging.set_log_device_placement(True)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "r0QpMH9dd4L6",
    "outputId": "cadab153-c369-4c3e-c5f0-9f7f48e641c0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras is installed and is version:  2.2.4-tf\n",
      "Tensorflow is installed and is version:  1.15.0\n",
      "Num GPUs Available:  2\n"
     ]
    }
   ],
   "source": [
    "print(\"Keras is installed and is version: \", tf.keras.__version__)\n",
    "print(\"Tensorflow is installed and is version: \",  tf.__version__)\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Zhcd6taffG92",
    "outputId": "f447b6ef-af68-43e4-c020-c1c0f87a4c7d"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Yg1_FF9yxz2I"
   },
   "outputs": [],
   "source": [
    "##Add seed to get reproducible results\n",
    "from numpy.random import seed\n",
    "seed(1)\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9hQv9pAVxsjC"
   },
   "outputs": [],
   "source": [
    "#https://www.tensorflow.org/tensorboard/get_started\n",
    "\n",
    "\"\"\"Helper Functions\"\"\"\n",
    "class TrainValTensorBoard(TensorBoard):\n",
    "    def __init__(self, log_dir='./logs', **kwargs):\n",
    "        # Make the original `TensorBoard` log to a subdirectory 'training'\n",
    "        training_log_dir = os.path.join(log_dir, 'training')\n",
    "        super(TrainValTensorBoard, self).__init__(training_log_dir, **kwargs)\n",
    "\n",
    "        # Log the validation metrics to a separate subdirectory\n",
    "        self.val_log_dir = os.path.join(log_dir, 'validation')\n",
    "\n",
    "    def set_model(self, model):\n",
    "        # Setup writer for validation metrics\n",
    "        self.val_writer = tf.summary.FileWriter(self.val_log_dir)\n",
    "        super(TrainValTensorBoard, self).set_model(model)\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        # Pop the validation logs and handle them separately with\n",
    "        # `self.val_writer`. Also rename the keys so that they can\n",
    "        # be plotted on the same figure with the training metrics\n",
    "        logs = logs or {}\n",
    "        val_logs = {k.replace('val_', ''): v for k, v in logs.items() if k.startswith('val_')}\n",
    "        for name, value in val_logs.items():\n",
    "            summary = tf.Summary()\n",
    "            summary_value = summary.value.add()\n",
    "            #summary_value.simple_value = value.item()\n",
    "            summary_value.tag = name\n",
    "            self.val_writer.add_summary(summary, epoch)\n",
    "        self.val_writer.flush()\n",
    "\n",
    "        # Pass the remaining logs to `TensorBoard.on_epoch_end`\n",
    "        logs = {k: v for k, v in logs.items() if not k.startswith('val_')}\n",
    "        super(TrainValTensorBoard, self).on_epoch_end(epoch, logs)\n",
    "\n",
    "    def on_train_end(self, logs=None):\n",
    "        super(TrainValTensorBoard, self).on_train_end(logs)\n",
    "        self.val_writer.close()  \n",
    "                \n",
    "## Code adapted from Section\n",
    "def plot(history):\n",
    "    acc = history.history['acc']\n",
    "    loss = history.history['loss']\n",
    "\n",
    "    epochs = range(len(acc))\n",
    "    plt.plot(epochs, acc, 'g-', label='Training accuracy', color = 'darkred')\n",
    "    plt.xlabel(\"Num of Epochs\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.title('Training accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.figure()\n",
    " \n",
    "    plt.plot(epochs, loss, 'g-', label='Training loss', color = 'darkred')\n",
    "    plt.xlabel(\"Num of Epochs\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title('Training loss')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "# class CustomSaver(keras.callbacks.Callback):\n",
    "# \tdef __init__(self):\n",
    "# \t\tself.epoch = 0\t\n",
    "# \t# This function is called when the training begins\n",
    "# \tdef on_train_begin(self, logs={}):\n",
    "# \t\t# Initialize the lists for holding the logs, losses and accuracies\n",
    "# \t\tself.losses = []\n",
    "# \t\tself.acc = []\n",
    "# \t\tself.logs = []\n",
    "# \tdef on_epoch_end(self, epoch, logs={}):\n",
    "# \t\t# Append the logs, losses and accuracies to the lists\n",
    "# \t\tself.logs.append(logs)\n",
    "# \t\tself.losses.append(logs.get('loss'))\n",
    "# \t\tself.acc.append(logs.get('acc')*100)\n",
    "# \t\t# save model and plt every 50 epochs\n",
    "# \t\tif (epoch+1) % 25 == 0:\n",
    "# \t\t\tsys.stdout.write(\"\\nAuto-saving model and plot after {} epochs to \".format(epoch+1)+\"\\n\"+modeldirectory + modelfileprefix + \"_\" + str(epoch+1).zfill(3) + \".model\\n\"+modeldirectory + modelfileprefix + \"_\" + str(epoch+1).zfill(3) + \".png\\n\\n\")\n",
    "# \t\t\tsys.stdout.flush()\n",
    "# \t\t\tself.model.save(modeldirectory + modelfileprefix + '_' + str(epoch+1).zfill(3) + '.model')\n",
    "# \t\t\tcopyfile(notesfile,modeldirectory + modelfileprefix + '_' + str(epoch+1).zfill(3) + '.notes');\n",
    "# \t\t\tN = numpy.arange(0, len(self.losses))\n",
    "# \t\t\t# Plot train loss, train acc, val loss and val acc against epochs passed\n",
    "# \t\t\tplt.figure()\n",
    "# \t\t\tplt.subplots_adjust(hspace=0.7)\n",
    "# \t\t\tplt.subplot(2, 1, 1)\n",
    "# \t\t\t# plot loss values\n",
    "# \t\t\tplt.plot(N, self.losses, label = \"train_loss\")\n",
    "# \t\t\tplt.title(\"Loss [Epoch {}]\".format(epoch+1))\n",
    "# \t\t\tplt.xlabel('Epoch')\n",
    "# \t\t\tplt.ylabel('Loss')\n",
    "# \t\t\tplt.subplot(2, 1, 2)\n",
    "# \t\t\t# plot accuracy values\n",
    "# \t\t\tplt.plot(N, self.acc, label = \"train_acc\")\n",
    "# \t\t\tplt.title(\"Accuracy % [Epoch {}]\".format(epoch+1))\n",
    "# \t\t\tplt.xlabel(\"Epoch\")\n",
    "# \t\t\tplt.ylabel(\"Accuracy %\")\n",
    "# \t\t\tplt.savefig(modeldirectory + modelfileprefix + '_' + str(epoch+1).zfill(3) + '.png')\n",
    "# \t\t\tplt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "h0EXyIlhyHQc"
   },
   "source": [
    "----------\n",
    "# 1.Read in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "f8NYWkFVd4MB",
    "outputId": "e6d339f0-da62-42fe-a3d5-33b13eb4b185"
   },
   "outputs": [],
   "source": [
    "# #Unzipping compressed data folder\n",
    "# file_name = \"/content/gdrive/My Drive/Pokemon MIDIs.zip\"\n",
    "  \n",
    "# # opening the zip file in READ mode \n",
    "# with ZipFile(file_name, 'r') as zip: \n",
    "#     # printing all the contents of the zip file \n",
    "#     # zip.printdir() \n",
    "  \n",
    "#     # extracting all the files \n",
    "#     print(\"Extracting all the files now...\") \n",
    "#     zip.extractall() \n",
    "#     print(\"Done!\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UaSEIJUWjgK8"
   },
   "outputs": [],
   "source": [
    "# def get_midi_pattern():\n",
    "#   for file in glob.glob(\"Pokemon MIDIs/*.mid\"):\n",
    "#     try:\n",
    "#       return music21.midi.getNumbersAsList(file)\n",
    "#     except:\n",
    "#       print ('Error reading {}'.format(file))\n",
    "#       return None\n",
    "\n",
    "# midi_pattern = get_midi_pattern()\n",
    "\n",
    "# def get_tones(midi_pattern):\n",
    "#   \"\"\"\n",
    "#   returns a dict of statistics, keys: [scale_distribution,\n",
    "#   \"\"\"\n",
    "  \n",
    "#   tones = []\n",
    "  \n",
    "#   for track in midi_pattern:\n",
    "#     for event in track:\n",
    "#       if type(event) == midi.events.SetTempoEvent:\n",
    "#         pass # These are currently ignored\n",
    "#       elif (type(event) == midi.events.NoteOffEvent) or \\\n",
    "#            (type(event) == midi.events.NoteOnEvent and \\\n",
    "#             event.velocity == 0):\n",
    "#         pass # not needed here\n",
    "#       elif type(event) == midi.events.NoteOnEvent:\n",
    "#         tones.append(event.data[0])\n",
    "#   return tones \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DDu2YuCZzckx"
   },
   "source": [
    "-----------\n",
    "# 2. Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "Y4fro8Au6M9k",
    "outputId": "f23fae6d-8557-461c-9d06-18024e205eee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "def get_notes():\n",
    "    notes = []\n",
    "    print(\"Parsing...\")\n",
    "    for file in glob.glob(\"Pokemon MIDIs/*.mid\"):\n",
    "        midi = converter.parse(file)\n",
    "\n",
    "      \n",
    "        notes_to_parse = None\n",
    "\n",
    "        try: # file has instrument parts\n",
    "            s2 = instrument.partitionByInstrument(midi)\n",
    "            notes_to_parse = s2.parts[0].recurse() \n",
    "        except: # file has notes in a flat structure\n",
    "            notes_to_parse = midi.flat.notes\n",
    "            \n",
    "        for element in notes_to_parse:\n",
    "            if isinstance(element, note.Note):\n",
    "                notes.append(str(element.pitch))\n",
    "            elif isinstance(element, chord.Chord):\n",
    "                notes.append('.'.join(str(n) for n in element.normalOrder))\n",
    "    \n",
    "    print(\"Done!\")\n",
    "    \n",
    "    return notes\n",
    "    # with open('content/pianonotes', 'wb') as filepath:\n",
    "    #     pickle.dump(notes, filepath)\n",
    "\n",
    "notes = get_notes()\n",
    "n_vocab = len(set(notes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oWKcxlL6y2lH"
   },
   "outputs": [],
   "source": [
    "def prepare_sequences(notes, n_vocab):\n",
    "    \"\"\" Prepare the sequences used by the Neural Network \"\"\"\n",
    "    sequence_length = 100\n",
    "\n",
    "    # get all pitch names\n",
    "    pitchnames = sorted(set(item for item in notes))\n",
    "\n",
    "     # create a dictionary to map pitches to integers\n",
    "    note_to_int = dict((note, number) for number, note in enumerate(pitchnames))\n",
    "\n",
    "    network_input = []\n",
    "    network_output = []\n",
    "\n",
    "    # create input sequences and the corresponding outputs\n",
    "    for i in range(0, len(notes) - sequence_length, 1):\n",
    "        sequence_in = notes[i:i + sequence_length]\n",
    "        sequence_out = notes[i + sequence_length]\n",
    "        network_input.append([note_to_int[char] for char in sequence_in])\n",
    "        network_output.append(note_to_int[sequence_out])\n",
    "\n",
    "    # reshape the input into a format compatible with LSTM layers\n",
    "    n_patterns = len(network_input)\n",
    "    network_input = np.reshape(network_input, (n_patterns, sequence_length, 1))\n",
    "    \n",
    "    # normalize input between 0 and 1\n",
    "    network_input = network_input / float(n_vocab)\n",
    "\n",
    "    network_output = np_utils.to_categorical(network_output)\n",
    "\n",
    "    return (network_input, network_output)\n",
    "\n",
    "network_input, network_output = prepare_sequences(notes, n_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ma_H3ieezmYz"
   },
   "source": [
    "-------\n",
    "# 3. Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 598
    },
    "colab_type": "code",
    "id": "XECJnlQi8sN1",
    "outputId": "48a20863-1cb9-49c8-f93e-4be24f84320f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "cu_dnngru_1 (CuDNNGRU)       (None, 100, 512)          791040    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 100, 512)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 100, 1024)         3151872   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 100, 1024)         0         \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, 1024)              4724736   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               262400    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 497)               127729    \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 497)               0         \n",
      "=================================================================\n",
      "Total params: 9,057,777\n",
      "Trainable params: 9,057,777\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "def cudnn_gru(network_input, n_vocab):\n",
    "    model = Sequential()\n",
    "    model.add(CuDNNGRU(512,input_shape=(network_input.shape[1], network_input.shape[2]), return_sequences=True))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Bidirectional(CuDNNGRU(512, return_sequences=True)))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Bidirectional(CuDNNGRU(512)))\n",
    "    model.add(Dense(256))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(n_vocab))\n",
    "    model.add(Activation('softmax'))\n",
    "    opt = RMSprop(lr=0.005)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "cudnngru = cudnn_gru(network_input, n_vocab)\n",
    "cudnngru.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WHaS330d0HIO"
   },
   "outputs": [],
   "source": [
    "##Add Checkpoint\n",
    "filepath = \"Weights/best_weights.hdf5\"\n",
    "checkpoint = ModelCheckpoint(\n",
    "    filepath,\n",
    "    monitor='loss',\n",
    "    verbose=0,\n",
    "    save_best_only=True,\n",
    "    mode='min'\n",
    ")\n",
    "\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 718
    },
    "colab_type": "code",
    "id": "6d1CNVDTukrX",
    "outputId": "54f9464a-ecd2-487c-fa82-8ccfb02ca1bf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "163585/163585 [==============================] - 290s 2ms/step - loss: 5.3896 - accuracy: 0.0135\n",
      "Epoch 2/60\n",
      "163585/163585 [==============================] - 290s 2ms/step - loss: 5.3485 - accuracy: 0.0132\n",
      "Epoch 3/60\n",
      "163585/163585 [==============================] - 290s 2ms/step - loss: 5.3393 - accuracy: 0.0136\n",
      "Epoch 4/60\n",
      "163585/163585 [==============================] - 290s 2ms/step - loss: 5.3096 - accuracy: 0.0135\n",
      "Epoch 5/60\n",
      "163585/163585 [==============================] - 290s 2ms/step - loss: 5.2900 - accuracy: 0.0139\n",
      "Epoch 6/60\n",
      "163585/163585 [==============================] - 290s 2ms/step - loss: 5.2811 - accuracy: 0.0140\n",
      "Epoch 7/60\n",
      "163585/163585 [==============================] - 290s 2ms/step - loss: 5.2720 - accuracy: 0.0144\n",
      "Epoch 8/60\n",
      "163585/163585 [==============================] - 290s 2ms/step - loss: 5.2621 - accuracy: 0.0137\n",
      "Epoch 9/60\n",
      "163585/163585 [==============================] - 290s 2ms/step - loss: 5.2549 - accuracy: 0.0139\n",
      "Epoch 10/60\n",
      "163585/163585 [==============================] - 290s 2ms/step - loss: 5.2512 - accuracy: 0.0140\n",
      "Epoch 11/60\n",
      "163585/163585 [==============================] - 289s 2ms/step - loss: 5.2461 - accuracy: 0.0143\n",
      "Epoch 12/60\n",
      "163585/163585 [==============================] - 289s 2ms/step - loss: 5.2457 - accuracy: 0.0145\n",
      "Epoch 13/60\n",
      "163585/163585 [==============================] - 289s 2ms/step - loss: 5.2437 - accuracy: 0.0139\n",
      "Epoch 14/60\n",
      "163585/163585 [==============================] - 289s 2ms/step - loss: 5.2409 - accuracy: 0.0142\n",
      "Epoch 15/60\n",
      "163585/163585 [==============================] - 290s 2ms/step - loss: 5.2422 - accuracy: 0.0140\n",
      "Epoch 16/60\n",
      "163585/163585 [==============================] - 289s 2ms/step - loss: 5.2423 - accuracy: 0.0142\n",
      "Epoch 17/60\n",
      "163585/163585 [==============================] - 290s 2ms/step - loss: 5.2440 - accuracy: 0.0140\n",
      "Epoch 18/60\n",
      "163585/163585 [==============================] - 290s 2ms/step - loss: 5.2441 - accuracy: 0.0141\n",
      "Epoch 19/60\n",
      "163585/163585 [==============================] - 291s 2ms/step - loss: 5.2469 - accuracy: 0.0140\n",
      "Epoch 20/60\n",
      "163585/163585 [==============================] - 290s 2ms/step - loss: 5.2445 - accuracy: 0.0143\n",
      "Epoch 21/60\n",
      "163585/163585 [==============================] - 290s 2ms/step - loss: 5.2467 - accuracy: 0.0141\n",
      "Epoch 22/60\n",
      "163585/163585 [==============================] - 289s 2ms/step - loss: 5.2469 - accuracy: 0.0140\n",
      "Epoch 23/60\n",
      "163585/163585 [==============================] - 289s 2ms/step - loss: 5.2461 - accuracy: 0.0144\n",
      "Epoch 24/60\n",
      "163585/163585 [==============================] - 289s 2ms/step - loss: 5.2476 - accuracy: 0.0137\n",
      "Epoch 25/60\n",
      "163585/163585 [==============================] - 289s 2ms/step - loss: 5.2457 - accuracy: 0.0142\n",
      "Epoch 26/60\n",
      "163585/163585 [==============================] - 289s 2ms/step - loss: 5.2432 - accuracy: 0.0143\n",
      "Epoch 27/60\n",
      "163585/163585 [==============================] - 289s 2ms/step - loss: 5.2411 - accuracy: 0.0146\n",
      "Epoch 28/60\n",
      "163585/163585 [==============================] - 290s 2ms/step - loss: 5.2307 - accuracy: 0.0146\n",
      "Epoch 29/60\n",
      "163585/163585 [==============================] - 289s 2ms/step - loss: 5.2307 - accuracy: 0.0141\n",
      "Epoch 30/60\n",
      "163585/163585 [==============================] - 289s 2ms/step - loss: 5.2289 - accuracy: 0.0144\n",
      "Epoch 31/60\n",
      "163585/163585 [==============================] - 289s 2ms/step - loss: 5.2286 - accuracy: 0.0149\n",
      "Epoch 32/60\n",
      "163585/163585 [==============================] - 289s 2ms/step - loss: 5.2291 - accuracy: 0.0139\n",
      "Epoch 33/60\n",
      "163585/163585 [==============================] - 289s 2ms/step - loss: 5.2286 - accuracy: 0.0150\n",
      "Epoch 34/60\n",
      "163585/163585 [==============================] - 289s 2ms/step - loss: 5.2235 - accuracy: 0.0141\n",
      "Epoch 35/60\n",
      "163585/163585 [==============================] - 289s 2ms/step - loss: 5.2185 - accuracy: 0.0146\n",
      "Epoch 36/60\n",
      "163585/163585 [==============================] - 288s 2ms/step - loss: 5.2141 - accuracy: 0.0145\n",
      "Epoch 37/60\n",
      "163585/163585 [==============================] - 289s 2ms/step - loss: 5.2112 - accuracy: 0.0146\n",
      "Epoch 38/60\n",
      "163585/163585 [==============================] - 289s 2ms/step - loss: 5.2123 - accuracy: 0.0142\n",
      "Epoch 39/60\n",
      "163585/163585 [==============================] - 290s 2ms/step - loss: 5.2152 - accuracy: 0.0149\n",
      "Epoch 40/60\n",
      "163585/163585 [==============================] - 291s 2ms/step - loss: 5.2157 - accuracy: 0.0143\n",
      "Epoch 41/60\n",
      "163585/163585 [==============================] - 291s 2ms/step - loss: 5.2169 - accuracy: 0.0148\n",
      "Epoch 42/60\n",
      "163585/163585 [==============================] - 291s 2ms/step - loss: 5.2164 - accuracy: 0.0146\n",
      "Epoch 43/60\n",
      "163585/163585 [==============================] - 291s 2ms/step - loss: 5.2156 - accuracy: 0.0141\n",
      "Epoch 44/60\n",
      "163585/163585 [==============================] - 291s 2ms/step - loss: 5.2176 - accuracy: 0.0141\n",
      "Epoch 45/60\n",
      "163585/163585 [==============================] - 291s 2ms/step - loss: 5.2140 - accuracy: 0.0139\n",
      "Epoch 46/60\n",
      "163585/163585 [==============================] - 291s 2ms/step - loss: 5.2129 - accuracy: 0.0143\n",
      "Epoch 47/60\n",
      "163585/163585 [==============================] - 291s 2ms/step - loss: 5.2141 - accuracy: 0.0147\n",
      "Epoch 48/60\n",
      "163585/163585 [==============================] - 291s 2ms/step - loss: 5.2164 - accuracy: 0.0144\n",
      "Epoch 49/60\n",
      "163585/163585 [==============================] - 291s 2ms/step - loss: 5.2158 - accuracy: 0.0143\n",
      "Epoch 50/60\n",
      "163585/163585 [==============================] - 291s 2ms/step - loss: 5.2161 - accuracy: 0.0144\n",
      "Epoch 51/60\n",
      "163585/163585 [==============================] - 289s 2ms/step - loss: 5.2160 - accuracy: 0.0141\n",
      "Epoch 52/60\n",
      "163585/163585 [==============================] - 289s 2ms/step - loss: 5.2193 - accuracy: 0.0142\n",
      "Epoch 53/60\n",
      "163585/163585 [==============================] - 290s 2ms/step - loss: 5.2219 - accuracy: 0.0145\n",
      "Epoch 54/60\n",
      "163585/163585 [==============================] - 290s 2ms/step - loss: 5.2205 - accuracy: 0.0136\n",
      "Epoch 55/60\n",
      "163585/163585 [==============================] - 290s 2ms/step - loss: 5.2209 - accuracy: 0.0146\n",
      "Epoch 56/60\n",
      "163585/163585 [==============================] - 290s 2ms/step - loss: 5.2180 - accuracy: 0.0145\n",
      "Epoch 57/60\n",
      "163585/163585 [==============================] - 290s 2ms/step - loss: 5.2168 - accuracy: 0.0145\n",
      "Epoch 58/60\n",
      "163585/163585 [==============================] - 290s 2ms/step - loss: 5.2153 - accuracy: 0.0143\n",
      "Epoch 59/60\n",
      "163585/163585 [==============================] - 290s 2ms/step - loss: 5.2142 - accuracy: 0.0145\n",
      "Epoch 60/60\n",
      "163585/163585 [==============================] - 290s 2ms/step - loss: 5.2147 - accuracy: 0.0143\n"
     ]
    }
   ],
   "source": [
    "%timeit\n",
    "tf.global_variables_initializer()\n",
    "history_gru = cudnngru.fit(\n",
    "    network_input,\n",
    "    network_output,\n",
    "    batch_size=50,\n",
    "    epochs=60,\n",
    "    verbose=1, \n",
    "    callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "cudnngru.save(\"cudnngru.mag\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "##CuDNNGRU\n",
    "prediction_output = generate_notes(cudnngru, notes, network_input, n_vocab)\n",
    "\n",
    "create_midi(prediction_output, 'gru_midi')\n",
    "# plot(history_gru)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fypx9cwM83mI"
   },
   "source": [
    "-----------\n",
    "## CuDNNGRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 459
    },
    "colab_type": "code",
    "id": "mXMM6twooDYt",
    "outputId": "229c87cf-f66d-4f58-bfd6-462ef83569bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "cu_dnnlstm_1 (CuDNNLSTM)     (None, 100, 512)          1054720   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 100, 512)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 100, 1024)         4202496   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 100, 1024)         0         \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, 1024)              6299648   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               262400    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 497)               127729    \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 497)               0         \n",
      "=================================================================\n",
      "Total params: 11,946,993\n",
      "Trainable params: 11,946,993\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "\n",
    "def cudnn_lstm(network_input, n_vocab):\n",
    "    \"\"\" create the structure of the neural network \"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(CuDNNLSTM(512,input_shape=(network_input.shape[1], network_input.shape[2]), return_sequences=True))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Bidirectional(CuDNNLSTM(512, return_sequences=True)))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Bidirectional(CuDNNLSTM(512)))\n",
    "    model.add(Dense(256))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(n_vocab))\n",
    "    model.add(Activation('softmax'))\n",
    "    opt = RMSprop(lr=0.005)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "cudnnlstm = cudnn_lstm(network_input, n_vocab)\n",
    "cudnnlstm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 375
    },
    "colab_type": "code",
    "id": "htvjFBZg8sXm",
    "outputId": "9fa0a070-7f66-4094-90e9-ddf1b79a208b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "163585/163585 [==============================] - 287s 2ms/step - loss: 4.9713 - accuracy: 0.0165\n",
      "Epoch 2/30\n",
      "163585/163585 [==============================] - 287s 2ms/step - loss: 4.9207 - accuracy: 0.0184\n",
      "Epoch 3/30\n",
      "163585/163585 [==============================] - 287s 2ms/step - loss: 4.9442 - accuracy: 0.0196\n",
      "Epoch 4/30\n",
      "163585/163585 [==============================] - 287s 2ms/step - loss: 4.9589 - accuracy: 0.0187\n",
      "Epoch 5/30\n",
      "163585/163585 [==============================] - 287s 2ms/step - loss: 4.9658 - accuracy: 0.0193\n",
      "Epoch 6/30\n",
      "163585/163585 [==============================] - 287s 2ms/step - loss: 4.9664 - accuracy: 0.0190\n",
      "Epoch 7/30\n",
      "163585/163585 [==============================] - 287s 2ms/step - loss: 4.9703 - accuracy: 0.0187\n",
      "Epoch 8/30\n",
      "163585/163585 [==============================] - 287s 2ms/step - loss: 4.9719 - accuracy: 0.0184\n",
      "Epoch 9/30\n",
      "163585/163585 [==============================] - 287s 2ms/step - loss: 4.9736 - accuracy: 0.0186\n",
      "Epoch 10/30\n",
      "163585/163585 [==============================] - 287s 2ms/step - loss: 4.9716 - accuracy: 0.0186\n",
      "Epoch 11/30\n",
      "163585/163585 [==============================] - 287s 2ms/step - loss: 4.9745 - accuracy: 0.0181\n",
      "Epoch 12/30\n",
      "163585/163585 [==============================] - 288s 2ms/step - loss: 4.9768 - accuracy: 0.0187\n",
      "Epoch 13/30\n",
      "163585/163585 [==============================] - 287s 2ms/step - loss: 4.9782 - accuracy: 0.0182\n",
      "Epoch 14/30\n",
      "163585/163585 [==============================] - 288s 2ms/step - loss: 4.9817 - accuracy: 0.0185\n",
      "Epoch 15/30\n",
      "163585/163585 [==============================] - 288s 2ms/step - loss: 4.9866 - accuracy: 0.0173\n",
      "Epoch 16/30\n",
      "163585/163585 [==============================] - 287s 2ms/step - loss: 4.9901 - accuracy: 0.0187\n",
      "Epoch 17/30\n",
      "163585/163585 [==============================] - 287s 2ms/step - loss: 4.9938 - accuracy: 0.0185\n",
      "Epoch 18/30\n",
      "163585/163585 [==============================] - 287s 2ms/step - loss: 4.9997 - accuracy: 0.0185\n",
      "Epoch 19/30\n",
      "163585/163585 [==============================] - 288s 2ms/step - loss: 5.0006 - accuracy: 0.0187\n",
      "Epoch 20/30\n",
      "163585/163585 [==============================] - 287s 2ms/step - loss: 5.0070 - accuracy: 0.0184\n",
      "Epoch 21/30\n",
      "163585/163585 [==============================] - 288s 2ms/step - loss: 5.0092 - accuracy: 0.0179\n",
      "Epoch 22/30\n",
      "163585/163585 [==============================] - 288s 2ms/step - loss: 5.0101 - accuracy: 0.0188\n",
      "Epoch 23/30\n",
      "163585/163585 [==============================] - 287s 2ms/step - loss: 5.0148 - accuracy: 0.0184\n",
      "Epoch 24/30\n",
      "163585/163585 [==============================] - 287s 2ms/step - loss: 5.0191 - accuracy: 0.0181\n",
      "Epoch 25/30\n",
      "163585/163585 [==============================] - 288s 2ms/step - loss: 5.0231 - accuracy: 0.0186\n",
      "Epoch 26/30\n",
      "163585/163585 [==============================] - 287s 2ms/step - loss: 5.0224 - accuracy: 0.0181\n",
      "Epoch 27/30\n",
      "163585/163585 [==============================] - 287s 2ms/step - loss: 5.0264 - accuracy: 0.0175\n",
      "Epoch 28/30\n",
      "163585/163585 [==============================] - 287s 2ms/step - loss: 5.0310 - accuracy: 0.0179\n",
      "Epoch 29/30\n",
      "163585/163585 [==============================] - 287s 2ms/step - loss: 5.0331 - accuracy: 0.0181\n",
      "Epoch 30/30\n",
      "163585/163585 [==============================] - 287s 2ms/step - loss: 5.0359 - accuracy: 0.0188\n"
     ]
    }
   ],
   "source": [
    "%timeit\n",
    "tf.global_variables_initializer()\n",
    "\n",
    "history_lstm = cudnnlstm.fit(\n",
    "    network_input,\n",
    "    network_output,\n",
    "    batch_size=64,\n",
    "    epochs=30,\n",
    "    verbose=1, \n",
    "    callbacks=[TrainValTensorBoard(\"logs/{}\".format(time()), write_graph=True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "73eQ3o908srw"
   },
   "outputs": [],
   "source": [
    "cudnnlstm.save(\"cudnnlstm.mag\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s9mJpTaZDhaw"
   },
   "source": [
    "--------------\n",
    "# Generate new soundclips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x5WW-uJ-ukyD"
   },
   "outputs": [],
   "source": [
    "def generate_notes(model, notes, network_input, n_vocab):\n",
    "    \"\"\" Generate notes from the neural network based on a sequence of notes \"\"\"\n",
    "    # pick a random sequence from the input as a starting point for the prediction\n",
    "    pitchnames = sorted(set(item for item in notes))\n",
    "    \n",
    "    start = np.random.randint(0, len(network_input)-1)\n",
    "\n",
    "    int_to_note = dict((number, note) for number, note in enumerate(pitchnames))\n",
    "\n",
    "    pattern = network_input[start]\n",
    "    prediction_output = []\n",
    "\n",
    "    # generate 500 notes\n",
    "    for note_index in range(500):\n",
    "        prediction_input = np.reshape(pattern, (1, len(pattern), 1))\n",
    "        prediction_input = prediction_input / float(n_vocab)\n",
    "\n",
    "        prediction = model.predict(prediction_input, verbose=0)\n",
    "\n",
    "        index = np.argmax(prediction)\n",
    "        result = int_to_note[index]\n",
    "        prediction_output.append(result)\n",
    "        \n",
    "        pattern = np.append(pattern,index)\n",
    "        pattern = pattern[1:len(pattern)]\n",
    "\n",
    "    return prediction_output\n",
    "\n",
    "def create_midi(prediction_output, filename):\n",
    "    \"\"\" convert the output from the prediction to notes and create a midi file\n",
    "        from the notes \"\"\"\n",
    "    offset = 0\n",
    "    output_notes = []\n",
    "\n",
    "    # create note and chord objects based on the values generated by the model\n",
    "    for pattern in prediction_output:\n",
    "        # pattern is a chord\n",
    "        if ('.' in pattern) or pattern.isdigit():\n",
    "            notes_in_chord = pattern.split('.')\n",
    "            notes = []\n",
    "            for current_note in notes_in_chord:\n",
    "                new_note = note.Note(int(current_note))\n",
    "                new_note.storedInstrument = instrument.Piano()\n",
    "                notes.append(new_note)\n",
    "            new_chord = chord.Chord(notes)\n",
    "            new_chord.offset = offset\n",
    "            output_notes.append(new_chord)\n",
    "        # pattern is a note\n",
    "        else:\n",
    "            new_note = note.Note(pattern)\n",
    "            new_note.offset = offset\n",
    "            new_note.storedInstrument = instrument.ChurchBells()\n",
    "            output_notes.append(new_note)\n",
    "        # increase offset each iteration so that notes do not stack\n",
    "        offset += 0.5\n",
    "\n",
    "    midi_stream = stream.Stream(output_notes)\n",
    "    midi_stream.write('midi', fp='{}.mid'.format(filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ej3_trUAc85a"
   },
   "source": [
    "## Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ULVC4mypdQnG"
   },
   "outputs": [],
   "source": [
    "##CuDNNLSTM\n",
    "prediction_output = generate_notes(cudnnlstm, notes, network_input, n_vocab)\n",
    "\n",
    "create_midi(prediction_output, 'lstm_midi')\n",
    "# plot(history_lstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D3u96sAu2TsC"
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H31QlhGFbiFY"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "CudNN_final.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
